# lely-demo

This repository is a tool to quickly get data
from [GitHub Events API](https://api.github.com/events) into a Mongo database,
and have it exposed/analysed via several dedicated APIs.

It is a Docker setup with 2 main containers based on Celery (including Beat), Spark, asyncio, FastAPI and Mongo.
Monitoring containers can be spin up e.g. Mongo Express and Flower.

The repository itself is based on the ['biggie' project](https://github.com/pierrz/biggie).

<br>


### Installation

#### Environment
You have to create the `.env` environment file.

**NB**:
- For all these required files, you'll find the `.env.example` file ready to adapt.

<br>

#### Build
The `docker-compose.main` file is structured to make the `test` containers build the image
used by the `prod` image. Hence the need to run one of the following commands on the very first run:
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml up api_test celery_test
OR
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml --profile test up
```

<br>

### Run
#### Data streaming from the GitHub API into Mongo
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml up celery_prod
```
This command will spin up the Celery container and:

  - download paginated data and save them as files locally
  - read these files and load Mongo with relevant data

At the moment, the frequency of this sequence is set to every minute.
And once a day at 03:00, the local files are being deleted.

<br>

#### API container
Just to have the FastAPI container up
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml up api_prod
```

<br>

#### Monitoring
Spin up the Mongo-Express container to access the Mongo UI
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml --profile monitoring up
```

<br>

#### The whole shebang (excluding tests containers)
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml --profile monitoring --profile prod up
```

<br>

### Nginx deployment (API container only)
In this configuration, you need to have the necessary sub-domains setup on your domain provider side.
You also need:
- Nginx installed on the host machine
- a certificate generated by `certbot` without any changes to nginx configuration (see [documentation](https://certbot.eff.org/instructions))
    ```
    sudo certbot certonly --nginx    # example command for ubuntu 20
    ```
<br>

Then create the required files and change the `volumes` path accordingly in the `compose` files.
The `nginx` configuration files are:

`conf/nginx/certificate.json`
`conf/nginx/app_docker.conf`
`conf/nginx/monitor_docker.conf`
<br>

Finally run the `docker-compose` command with the `live_prod` profile:
```
docker-compose -f docker-compose.main.yml -f docker-compose.mongo.yml --profile live_prod up
```

<br>

### Local URLs

[API docs](http://localhost:8000/docs)

API - PR average delta for a given repository
http://localhost:8000/api/pr_average_delta?repo_name=<repository-name>

API - Count per type with a given time offset in minutes
http://localhost:8000/api/count_per_type?offset=90

API - Timeline of PR deltas for a given repository (dataviz)
http://localhost:8000/api/pr_deltas_timeline?repo_name=<repository-name>

NB: a repository name includes the actor name such as `pierrz/biggie`

Monitoring
- [Mongo-Express](http://localhost:8081)
- [Flower](http://localhost:49555)

<br>

### Local development
If you want to make some changes in this repo while following the same environment tooling,
you can run the following command from the root directory:
```
poetry config virtualenvs.in-project true
poetry install && poetry shell
pre-commit install
```

To change the code of the core containers, you need to `cd` to the related directory
and either:
- run `poetry update` to simply install the required dependencies
- run the previous command to create a dedicated virtualenv
